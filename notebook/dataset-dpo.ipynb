{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies は初回のみ実行\n",
    "# %pip install ipywidgets bitsandbytes peft pyzmq transformers trl datasets sentencepiece accelerate wandb huggingface_hub argilla python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache系は必ずteam storageへ\n",
    "# TEAM_DATASETS_CACHE_DIR=\"/persistentshare/storage/team_kumagai/datasets\"\n",
    "TEAM_DATASETS_CACHE_DIR = \"./.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "from huggingface_hub import login, whoami\n",
    "\n",
    "import argilla as rg\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    set_seed,\n",
    "    Seq2SeqTrainer,\n",
    "    BitsAndBytesConfig,\n",
    "    LlamaTokenizer,\n",
    "    TrainerCallback,\n",
    ")\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from trl import DPOTrainer\n",
    "\n",
    "import torch.distributed as dist\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(\"start logging...!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=os.getenv(\"WANDB_PROJECT\"),\n",
    "    entity=os.getenv(\"WANDB_ENTITY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.init(\n",
    "    api_url=os.getenv(\"RG_API_URL\"),\n",
    "    api_key=os.getenv(\"RG_API_KEY\"),\n",
    "    workspace=os.getenv(\"RG_WORKSPACE\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admin userならば、以下のコードでユーザー一覧を取得できる\n",
    "# rg.User.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.Workspace.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = rg.Workspace.from_name(os.getenv(\"RG_WORKSPACE\"))\n",
    "workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm-jpの翻訳版 hh-rlhf を使う\n",
    "# ライセンスはMIT\n",
    "# https://huggingface.co/datasets/llm-jp/hh-rlhf-12k-ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_use = load_dataset(\"llm-jp/hh-rlhf-12k-ja\", cache_dir=TEAM_DATASETS_CACHE_DIR)\n",
    "dataset_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourceのuniqueな値を取得\n",
    "source = dataset_use[\"train\"][\"source\"]\n",
    "# setでユニークな値を取得\n",
    "source_set = set(source)\n",
    "source_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1件目を確認\n",
    "dataset_use[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10件目を確認\n",
    "dataset_use[\"train\"][10 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1500件目を確認\n",
    "dataset_use[\"train\"][1500 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000件目を確認\n",
    "dataset_use[\"train\"][10000 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12000件目のデータを確認\n",
    "dataset_use[\"train\"][12000 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_dpo_format(data: dict[str, Any]):\n",
    "    # content: str\n",
    "    # role: user or assistant\n",
    "    # の構成に直す\n",
    "    conversations: list[dict[str, str]] = data[\"conversations\"]\n",
    "\n",
    "    replace: list[dict[str, str]] = []\n",
    "    # from: human or gpt\n",
    "    # value: str\n",
    "    # で構成されるので分離するが、contentが消えている？\n",
    "    for conversation in conversations:\n",
    "        str_value = conversation[\"value\"]\n",
    "\n",
    "        # fromをroleに変換\n",
    "        str_from = conversation[\"from\"]\n",
    "        if str_from == \"human\":\n",
    "            str_from = \"user\"\n",
    "        elif str_from == \"gpt\":\n",
    "            str_from = \"assistant\"\n",
    "        else:\n",
    "            logger.error(f\"from is invalid: {str_from}\")\n",
    "            raise ValueError(\"unreachable\")\n",
    "\n",
    "        replace.append(\n",
    "            {\n",
    "                \"content\": str_value.strip(),\n",
    "                \"role\": str_from,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    chosen: str = data[\"chosen\"]\n",
    "    rejected: str = data[\"rejected\"]\n",
    "    chosen_set = replace.copy()\n",
    "    rejected_set = replace.copy()\n",
    "\n",
    "    # 最後が user の場合は、新しく assistant を追加する\n",
    "    # 最後が assistant の場合は、assistant の content に追加する\n",
    "    chosen_last = chosen_set[-1]\n",
    "    if chosen_last[\"role\"] == \"user\":\n",
    "        chosen_set.append(\n",
    "            {\n",
    "                \"content\": chosen.strip(),\n",
    "                \"role\": \"assistant\",\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        chosen_last[\"content\"] += \"\" + chosen.strip()\n",
    "\n",
    "    rejected_last = rejected_set[-1]\n",
    "    if rejected_last[\"role\"] == \"user\":\n",
    "        rejected_set.append(\n",
    "            {\n",
    "                \"content\": rejected.strip(),\n",
    "                \"role\": \"assistant\",\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        rejected_last[\"content\"] += \"\" + rejected.strip()\n",
    "\n",
    "    # 他はmetadataとして追加\n",
    "    source: str = data[\"source\"]\n",
    "\n",
    "    return {\n",
    "        \"chosen\": chosen_set,\n",
    "        \"rejected\": rejected_set,\n",
    "        \"metadata\": {\n",
    "            \"source\": source,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def dpo_format_to_field(data: list[dict[str, str]]):\n",
    "    # role: user or assistant\n",
    "    # content: str\n",
    "    # をfieldの表示形式に変換する\n",
    "    ret = \"\"\n",
    "    for item in data:\n",
    "        role = item[\"role\"]\n",
    "        content = item[\"content\"]\n",
    "        ret += f\"{role}: {content}\\n\"\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = data_to_dpo_format(dataset_use[\"train\"][10000 - 1])\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dpo_format_to_field(test1[\"chosen\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部を変換する\n",
    "train_dataset_use = dataset_use[\"train\"].map(data_to_dpo_format)\n",
    "# sourceとconversationsのkeyは消す\n",
    "train_dataset_use = train_dataset_use.remove_columns([\"source\", \"conversations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_use[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_use[10000 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fields():\n",
    "    return [\n",
    "        rg.TextField(name=\"chosen\"),\n",
    "        rg.TextField(name=\"rejected\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_questions():\n",
    "    return [\n",
    "        rg.RatingQuestion(\n",
    "            name=\"chosen_rating\",\n",
    "            values=[1, 2, 3, 4, 5],\n",
    "            required=True,\n",
    "        ),\n",
    "        rg.RatingQuestion(\n",
    "            name=\"rejected_rating\",\n",
    "            values=[1, 2, 3, 4, 5],\n",
    "            required=True,\n",
    "        ),\n",
    "        rg.TextQuestion(\n",
    "            name=\"modify_chosen\",\n",
    "            required=False,\n",
    "        ),\n",
    "        rg.TextQuestion(\n",
    "            name=\"modify_rejected\",\n",
    "            required=False,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_metadata_properties():\n",
    "    return [\n",
    "        rg.TermsMetadataProperty(\n",
    "            name=\"source\",\n",
    "            values=[\n",
    "                \"harmless-base\",\n",
    "                \"helpful-base\",\n",
    "                \"helpful-online\",\n",
    "                \"helpful-rejection-sampled\",\n",
    "            ],\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_record(data: dict[str, str]):\n",
    "    return rg.FeedbackRecord(\n",
    "        fields={\n",
    "            \"chosen\": dpo_format_to_field(data[\"chosen\"]),\n",
    "            \"rejected\": dpo_format_to_field(data[\"rejected\"]),\n",
    "        },\n",
    "        # TODO: suggestionsでmodify_chosenとmodify_rejectedを追加する\n",
    "        # suggestions=[\n",
    "        #     {\n",
    "        #         \"question_name\": \"modify_chosen\",\n",
    "        #         \"value\": \"\",\n",
    "        #     }\n",
    "        # ]\n",
    "        metadata=data[\"metadata\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_record(train_dataset_use[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rg_dataset(dataset_use):\n",
    "    rg_dataset = rg.FeedbackDataset(\n",
    "        guidelines=\"hh-rlhfのデータセットを使って、chosenとrejectedを評価してください。必要があれば最後のassistantの文章のみを修正してください。\",\n",
    "        fields=get_fields(),\n",
    "        questions=get_questions(),\n",
    "        metadata_properties=get_metadata_properties(),\n",
    "    )\n",
    "    # to_recordを使って全て変換する\n",
    "    rg_records = [to_record(data) for data in dataset_use]\n",
    "    \n",
    "    # ログで確認\n",
    "    logger.info(f\"rg_records: {rg_records}\")\n",
    "    \n",
    "    rg_dataset.add_records(rg_records)\n",
    "    \n",
    "    return rg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_dataset = create_rg_dataset(train_dataset_use)\n",
    "# pushする\n",
    "# remote_rg_dataset = rg_dataset.push_to_argilla(\n",
    "#     name=\"second-hh-rlhf-12k-ja\", workspace=workspace, show_progress=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_rg_dataset を hf にpushする\n",
    "# remote_rg_dataset.push_to_huggingface(\n",
    "#     \"hironow/test-hh-rlhf-12k-ja\", generate_card=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
